{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syoooooung/capstone_design/blob/main/Query_Decomposition/%5Bfinal_form%5Dsubquery_by_conjunction_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "neejavMDpnhx",
        "outputId": "aecf58f9-2758-4410-fea6-022c27a84b58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.9)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.5)\n",
            "Collecting ragas\n",
            "  Downloading ragas-0.2.8-py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting groq\n",
            "  Downloading groq-0.13.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.11-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting anls\n",
            "  Downloading anls-0.0.2-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.9)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.21)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Collecting tiktoken (from ragas)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting langchain_openai (from ragas)\n",
            "  Downloading langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ragas) (1.6.0)\n",
            "Collecting appdirs (from ragas)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting pysbd>=0.3.4 (from ragas)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.11-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.21 (from langchain)\n",
            "  Downloading langchain_core-0.3.24-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.46.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (11.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n",
            "Collecting openai\n",
            "  Downloading openai-1.57.2-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain) (3.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Downloading ragas-0.2.8-py3-none-any.whl (173 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.9/173.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-0.13.0-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.11-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.11-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anls-0.0.2-py3-none-any.whl (12 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.24-py3-none-any.whl (410 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading langchain_openai-0.2.12-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.57.2-py3-none-any.whl (389 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.9/389.9 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: appdirs, xxhash, python-dotenv, pysbd, mypy-extensions, marshmallow, httpx-sse, fsspec, faiss-cpu, dill, anls, typing-inspect, tiktoken, multiprocess, pydantic-settings, openai, groq, dataclasses-json, langchain-core, langchain_openai, datasets, langchain, evaluate, langchain_community, ragas\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.54.5\n",
            "    Uninstalling openai-1.54.5:\n",
            "      Successfully uninstalled openai-1.54.5\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.21\n",
            "    Uninstalling langchain-core-0.3.21:\n",
            "      Successfully uninstalled langchain-core-0.3.21\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.9\n",
            "    Uninstalling langchain-0.3.9:\n",
            "      Successfully uninstalled langchain-0.3.9\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed anls-0.0.2 appdirs-1.4.4 dataclasses-json-0.6.7 datasets-3.2.0 dill-0.3.8 evaluate-0.4.3 faiss-cpu-1.9.0.post1 fsspec-2024.9.0 groq-0.13.0 httpx-sse-0.4.0 langchain-0.3.11 langchain-core-0.3.24 langchain_community-0.3.11 langchain_openai-0.2.12 marshmallow-3.23.1 multiprocess-0.70.16 mypy-extensions-1.0.0 openai-1.57.2 pydantic-settings-2.6.1 pysbd-0.3.4 python-dotenv-1.0.1 ragas-0.2.8 tiktoken-0.8.0 typing-inspect-0.9.0 xxhash-3.5.0\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.2.12)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.3.24)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.55.3 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.57.2)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.8.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (0.1.147)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (0.28.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (0.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (4.66.6)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.55.3->langchain-openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.55.3->langchain-openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain-openai) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.21->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.21->langchain-openai) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai ragas datasets faiss-cpu groq langchain_community evaluate anls sentence_transformers\n",
        "!pip install -U langchain-openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlVNwx60xvEX",
        "outputId": "5af49519-02c9-4802-ef26-50070ef014a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from langchain.vectorstores import FAISS\n",
        "import faiss\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from google.colab import drive, userdata\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY2')\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FqSZIExbWeA"
      },
      "outputs": [],
      "source": [
        "data= [\n",
        "    {\n",
        "        \"question\": \"Which American singer and songwriter has a mezzo-sprano vocal range, Tim Arm or Tori Amos?\",\n",
        "        \"answer\": \"Sam Bankman-Fried\",\n",
        "        \"decomposed\": [\n",
        "            \"Who is the individual associated with the cryptocurrency industry facing a criminal trial on fraud and conspiracy charges?\",\n",
        "            \"Who is accused by prosecutors of committing fraud for personal gain in the cryptocurrency industry?\",\n",
        "            \"What industry is the individual associated with who is facing a criminal trial on fraud and conspiracy charges?\",\n",
        "            \"Who has been reported by The Verge and TechCrunch in relation to a criminal trial on fraud and conspiracy charges?\"\n",
        "        ],\n",
        "        \"supporting_facts_sentences\": [\n",
        "            \"Before his fall, Bankman-Fried made himself out to be the Good Boy of crypto — the trustworthy face of a sometimes-shady industry.\",\n",
        "            \"The highly anticipated criminal trial for Sam Bankman-Fried, former CEO of bankrupt crypto exchange FTX, started Tuesday to determine whether he’s guilty of seven counts of fraud and conspiracy.\",\n",
        "            \"The prosecution painted Bankman-Fried as someone who knowingly committed fraud to achieve great wealth, power and influence, while the defense countered that the FTX founder acted in good faith, never meant to commit fraud or steal and basically got in over his head.\"\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "# input 파일 형태 예시"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install openai==1.55.3 httpx==0.27.2 --force-reinstall --quiet"
      ],
      "metadata": {
        "id": "5IbDs7accs-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "OwLpL3CGct_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P295dPdYaFw7",
        "outputId": "a86ca9f0-21e4-40ff-cd91-23639cebf32e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Who's birth date is the first earliest\", 'among the birth date of Neil Armstrong', 'the first human to set foot on the Moon during the Apollo 11 mission in 1969', 'whose historic words, \"That\\'s one small step for [a] man, one giant leap for mankind,\" marked a significant achievement in space exploration', 'Taylor Swift', 'Chris Hemsworth?']\n",
            "[\"Who's birth date is the second earliest\", 'among the birth date of Neil Armstrong', 'the first human to set foot on the Moon during the Apollo 11 mission in 1969', 'whose famous words, \"That\\'s one small step for [a] man, one giant leap for mankind,\" marked a pivotal moment in space exploration', 'Taylor Swift', 'Will Smith?']\n",
            "[\"Who's birth date is the third earliest\", 'among the birth date of Neil Armstrong', 'the first human to set foot on the Moon during the Apollo 11 mission in 1969', 'whose famous words \"That\\'s one small step for [a] man, one giant leap for mankind\" marked a significant achievement in space exploration', 'Taylor Swift', 'Vincent van Gogh?']\n",
            "[\"Who's birth date is the first earliest\", 'among the birth date of Neil Armstrong', 'the first human to set foot on the Moon during the Apollo 11 mission in 1969', 'whose historic words, \"That\\'s one small step for [a] man, one giant leap for mankind,\" marked a pivotal moment in space exploration', 'Taylor Swift', 'Margot Robbie?']\n",
            "[\"Who's birth date is the second earliest\", 'among the birth date of Neil Armstrong', 'the first human to set foot on the Moon during the Apollo 11 mission in 1969', 'a monumental achievement in space exploration that marked a significant milestone in human history', 'Vladimir Putin', 'Chris Hemsworth?']\n",
            "[\"Who's birth date is the third earliest\", 'among the birth date of Neil Armstrong', 'the first human to set foot on the Moon during the Apollo 11 mission in 1969', 'a monumental achievement in space exploration that marked a significant milestone in human history', 'Vladimir Putin', 'Will Smith?']\n",
            "[\"Who's birth date is the first earliest\", 'among the birth date of Neil Armstrong', 'the first human to set foot on the Moon during the Apollo 11 mission in 1969', 'whose famous words \"That\\'s one small step for [a] man, one giant leap for mankind\" marked a significant achievement in space exploration', 'Vladimir Putin', 'Leonardo da Vinci?']\n",
            "[\"Who's birth date is the second earliest\", 'among the birth date of Neil Armstrong', 'the first human to set foot on the Moon during the Apollo 11 mission in 1969', 'whose famous words \"That\\'s one small step for [a] man, one giant leap for mankind\" marked a significant moment in human history', 'Vladimir Putin', 'Margot Robbie?']\n",
            "[\"Who's birth date is the third earliest\", 'among the birth date of Neil Armstrong', 'the first human to set foot on the Moon during the Apollo 11 mission in 1969', 'an iconic figure in space exploration whose famous words, \"That\\'s one small step for [a] man, one giant leap for mankind,\" resonate through history', 'Donald Trump', 'Leonardo DiCaprio?']\n",
            "[\"Who's birth date is the first earliest\", 'among the birth date of Neil Armstrong', 'the first human to set foot on the Moon during the Apollo 11 mission in 1969', 'whose famous words \"That\\'s one small step for [a] man, one giant leap for mankind\" marked a significant achievement in space exploration', 'Donald Trump', 'Mark Zuckerberg?']\n",
            "JSON file updated and saved successfully.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import json\n",
        "import openai\n",
        "\n",
        "# Load JSON data from file\n",
        "input_path = \"/content/selfgen_test_noqd.json\"  #input 파일 경로\n",
        "output_path = \"/content/selfgen_s_noqd.json\"  # 결과 저장 경로\n",
        "model = \"gpt-4o\"  # Replace with your model if needed\n",
        "\n",
        "\n",
        "def split_sentence(text):\n",
        "    # 예외 처리할 접속사 패턴\n",
        "    exception_patterns = [\n",
        "        r'\\b(?:both|either|neither)\\b.*?\\b(?:and|or|nor)\\b',\n",
        "        r'\\b(?:not only)\\b.*?\\b(?:but also)\\b'\n",
        "    ]\n",
        "\n",
        "    # 큰따옴표 내부의 내용을 보호하기 위해 콤마를 임시 치환\n",
        "    text = re.sub(r'(\".*?\")', lambda match: match.group(0).replace(\",\", \"_COMMA_\"), text)\n",
        "\n",
        "    # 예외 패턴을 먼저 처리하여 접속사 뒤에 있는 것들은 쪼개지 않도록 함\n",
        "    for pattern in exception_patterns:\n",
        "        text = re.sub(pattern, lambda match: match.group(0).replace(\" \", \"_EXCEPTION_\"), text)\n",
        "\n",
        "    # 접속사 및 콤마 기준으로 분리\n",
        "    conjunctions = r'\\b(?:and|or|but|so|nor)\\b'\n",
        "    parts = re.split(fr'\\s*(?:{conjunctions}|,)\\s*', text)\n",
        "\n",
        "    # 예외 패턴에 대해서는 다시 복원\n",
        "    parts = [part.replace(\"_COMMA_\", \",\").replace(\"_EXCEPTION_\", \" \") for part in parts]\n",
        "\n",
        "    # 후처리: 큰따옴표로 시작하는 부분을 만나면 바로 앞 세션 하나와만 병합\n",
        "    merged_parts = []\n",
        "    i = 0\n",
        "    while i < len(parts):\n",
        "        part = parts[i].strip()\n",
        "\n",
        "        # 큰따옴표로 시작하는 세션을 만났을 때\n",
        "        if part.startswith('\"'):\n",
        "            # 앞의 세션과 병합\n",
        "            if merged_parts:\n",
        "                merged_parts[-1] = merged_parts[-1].strip() + \", \" + part\n",
        "            else:\n",
        "                merged_parts.append(part)\n",
        "        else:\n",
        "            merged_parts.append(part)\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    # 결과 반환\n",
        "    merged_parts = [part for part in merged_parts if part]\n",
        "    print(merged_parts)\n",
        "    return merged_parts\n",
        "\n",
        "Instruction_str = \"\"\"\n",
        "Given a query with multiple entities or phrases separated by conjunctions or commas, create each sub-sentence by keeping as much of the original phrasing as necessary to maintain the intent and meaning of the original query.\n",
        "\n",
        "Instructions:\n",
        "1. For each separated part, complete the meaning of the sentence using the previous part of the current section.\n",
        "2. Preserve original terminology wherever possible, guaranteeing that each sub-sentence forms a grammatically complete sentence.\n",
        "3. The number of sub-sentences created must match the number of separated parts.\n",
        "\n",
        "\"\"\"\n",
        "#######################MultihopRAG333333333333#####################\n",
        "# 서브쿼리 생성 프롬프트\n",
        "def generate_subqueries2(original_query, split_results):\n",
        "    prompt = f\"\"\"\n",
        "Original Query: \"{original_query}\"\n",
        "Separated Parts:\n",
        "{split_results}\n",
        "\n",
        "Example:\n",
        "Original Query: \"Who is the individual associated with the cryptocurrency industry facing a criminal trial on fraud and conspiracy charges, as reported by both The Verge and TechCrunch, and is accused by prosecutors of committing fraud for personal gain?\"\n",
        "Seperated Parts: ['Who is the individual associated with the cryptocurrency industry facing a criminal trial on fraud', 'conspiracy charges', 'as reported by both The Verge and TechCrunch', 'is accused by prosecutors of committing fraud for personal gain?']\n",
        "->\n",
        "- subquery: Who is the individual associated with the cryptocurrency industry facing a criminal trial on fraud charges?\n",
        "- subquery: Who is the individual associated with the cryptocurrency industry facing conspiracy charges?\n",
        "- subquery: Who is the individual associated with the cryptocurrency industry, as reported by both The Verge and TechCrunch?\n",
        "- subqeury: Who is the individual is accused by prosecutors of committing fraud for personal gain?\n",
        "\n",
        "\n",
        "Example:\n",
        "Original Query: \"Who's birth date is the first earliest, among the birth date of Neil Armstrong, the first human to set foot on the Moon during the Apollo 11 mission in 1969, whose historic words, \\\"That's one small step for a man, one giant leap for mankind\\\", marked a significant achievement in space exploration, Taylor Swift, and Chris Hemsworth?\"\n",
        "Seperated Parts: ['Who's birth date is the first earliest', 'among the birth date of Neil Armstrong', 'the first human to set foot on the Moon during the Apollo 11 mission in 1969', 'whose historic words, \"That's one small step for a man, one giant leap for mankind\"', 'marked a significant achievement in space exploration', Taylor Swift', 'Chris Hemsworth?']\n",
        "->\n",
        "- subquery: Who's birth date is the first earliest?\n",
        "- subquery: What is the birth date of Neil Armstrong?\n",
        "- subquery: Was Neil Armstrong the first human to set foot on the Moon during the Apollo 11 mission in 1969?\n",
        "- subqeury: Is historic words of Neil Armstrong \\\"That's one small step for a man, one giant leap for mankind\\\"?\n",
        "- subqeury: Is historic words of Neil Armstrong mark a significant achievement in space exploration?\n",
        "- subqeury: What is the birth date of Taylor Swift?\n",
        "- subqeury: What is the birth date of Chris Hemsworth?\n",
        "\n",
        "\n",
        "Now, based on the above examples, provide a list of subqueries for each part of the sentence while preserving the essential meaning.\n",
        "Don't say anything other than the format that starts with this form (- subquery: ). And the decomposed query that is generated can't just generate the original question. Don't forget the purpose of dividing in the original question.\n",
        "\"\"\"\n",
        "    return prompt\n",
        "\n",
        "# LLM 호출 예시\n",
        "def get_subqueries2(original_query, model=\"gpt-4o\"):\n",
        "    split_results = split_sentence(original_query)\n",
        "    prompt = generate_subqueries2(original_query, split_results)\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": Instruction_str},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "        temperature=0\n",
        "    )\n",
        "\n",
        "    # 각 서브쿼리의 앞에 있는 \"subquery:\"와 \"-\"를 제거하고 리스트로 반환\n",
        "    subqueries = [\n",
        "        query.replace(\"- subquery: \", \"\").strip()  # \"subquery:\" 제거\n",
        "        for query in response.choices[0].message.content.splitlines() if query.strip()\n",
        "    ]\n",
        "    return subqueries\n",
        "\n",
        "# JSON 데이터 처리 함수\n",
        "def process_json(data):\n",
        "    processed_entries = []\n",
        "    cnt=0\n",
        "    for entry in data:\n",
        "        cnt+=1\n",
        "        if cnt >100:\n",
        "            continue\n",
        "        if cnt >10:\n",
        "            break\n",
        "\n",
        "        processed_entry = {\n",
        "            \"question\": entry[\"question\"],\n",
        "            \"gt_ans\": entry[\"gt_ans\"],\n",
        "            #\"gt_doc\": entry.get(\"gt_doc\", []),\n",
        "            \"question_d\": get_subqueries2(entry[\"question\"])\n",
        "        }\n",
        "        processed_entries.append(processed_entry)\n",
        "    return processed_entries\n",
        "\n",
        "# Load and process JSON\n",
        "with open(input_path, 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "processed_data = process_json(data)\n",
        "\n",
        "# Save the updated JSON file\n",
        "with open(output_path, 'w', encoding='utf-8') as file:\n",
        "    json.dump(processed_data, file, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(\"JSON file updated and saved successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSyA0r7bPZYl"
      },
      "source": [
        "## 프롬프트 HotpotVer & MulithopRAG ver\n",
        "hotpot과 Multihoop 각각 프롬프트를 다르게 줘서 해당하는 것 진행할때 아래에서 가져다 쓰면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MLTyHoYPdeW"
      },
      "outputs": [],
      "source": [
        "#######################MultihopRAG#####################\n",
        "# 서브쿼리 생성 프롬프트\n",
        "def generate_subqueries2(original_query, split_results):\n",
        "    prompt = f\"\"\"\n",
        "Given a query with multiple entities or phrases separated by conjunctions or commas, create each subquery by keeping as much of the original phrasing as necessary to maintain the intent and meaning of the original query.\n",
        "\n",
        "Instructions:\n",
        "1. For each phrase or section after a conjunction or comma, create a complete subquery that retains necessary context from the original query.\n",
        "2. Ensure each subquery stands alone with full context so no information or intent is lost, and no subquery is overly simplified.\n",
        "3. Maintain original terms where possible and ensure each subquery is grammatically complete.\n",
        "\n",
        "Original Query: \"{original_query}\"\n",
        "Separated Parts:\n",
        "{split_results}\n",
        "\n",
        "Example:\n",
        "Original Query: \"What is the name of the organization discussed in TechCrunch articles that, despite its financial instability, is recognized for creating ChatGPT, which is both a priority and a platform for ongoing innovations, and is planning to enhance its capabilities with the release of GPT-4 and associated APIs?\"\n",
        "->\n",
        "- subquery: What is the name of the organization recognized for creating ChatGPT?\n",
        "- subquery: What is the name of the organization recognized for creating ChatGPT, which is both a priority and a platform for ongoing innovations?\n",
        "- subquery: What is the name of the organization planning to enhance ChatGPT with the release of GPT-4 and associated APIs?\n",
        "- subquery: What is the name of the organization discussed in TechCrunch articles, despite its financial instability?\n",
        "\n",
        "Example:\n",
        "Original Query: \"profit of Apple, Tesla and Microsoft?\"\n",
        "->\n",
        "- subquery: profit of Apple\n",
        "- subquery: profit of Tesla\n",
        "- subquery: profit of Microsoft\n",
        "\n",
        "Another Example:\n",
        "Original Query: \"Which company, as reported by both TechCrunch and The Verge, has spent billions to maintain its default search engine status on various platforms and is also accused of harming news publishers’ revenue through its business practices?\"\n",
        "- subquery: Which company has spent billions to maintain its default search engine status on various platforms?\n",
        "- subquery: Which company is accused of harming news publishers’ revenue through its business practices?\n",
        "- subquery: Which company is reported by both TechCrunch and The Verge for these actions?\n",
        "\n",
        "One more example:\n",
        "Original Query: \"Who is the individual associated with the cryptocurrency industry facing a criminal trial on fraud and conspiracy charges, as reported by both The Verge and TechCrunch, and is accused by prosecutors of committing fraud for personal gain?\"\n",
        "->\n",
        "- subquery: Who is the individual associated with the cryptocurrency industry facing a criminal trial on fraud?\n",
        "- subquery: Who is the individual associated with the cryptocurrency industry facing a criminal trial conspiracy charges?\n",
        "- subquery: Who is the individual associated with the cryptocurrency industry as reported by The Verge?\n",
        "- subquery: Who is the individual associated with the cryptocurrency industry as reported by TechCrunch?\n",
        "- subquery: Who is the individual is accused by prosecutors of committing fraud for personal gain?\n",
        "\n",
        "Now, based on the above examples, provide a list of subqueries for each part of the question while preserving the essential meaning.\n",
        "- subquery: <- Don't say anything other than the format that starts with this form. And the decomposed query that is generated can't just generate the original question. Don't forget the purpose of dividing in the original question.\n",
        "\"\"\"\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######################MultihopRAG22222222222222222222#####################\n",
        "# 서브쿼리 생성 프롬프트\n",
        "def generate_subqueries2(original_query, split_results):\n",
        "    prompt = f\"\"\"\n",
        "Given a query with multiple entities or phrases separated by conjunctions or commas, create each subquery by keeping as much of the original phrasing as necessary to maintain the intent and meaning of the original query.\n",
        "\n",
        "Instructions:\n",
        "1. Look for an omission at the beginning of the current section to create a full subquery that maintains the context required in the original query for each phrase or section that follows an conjunction or comma.\n",
        "2. Ensure that each subquery stands independently with comprehensive context, preventing any loss of information or intent, and avoiding excessive simplification.\n",
        "3. Preserve original terminology wherever possible, guaranteeing that each subquery forms a grammatically complete sentence.\n",
        "\n",
        "Original Query: \"{original_query}\"\n",
        "Separated Parts:\n",
        "{split_results}\n",
        "\n",
        "Example:\n",
        "Original Query: \"What is the name of the organization discussed in TechCrunch articles that, despite its financial instability, is recognized for creating ChatGPT, which is both a priority and a platform for ongoing innovations, and is planning to enhance its capabilities with the release of GPT-4 and associated APIs?\"\n",
        "Seperated Parts: ['What is the name of the organization discussed in TechCrunch articles that', 'despite its financial instability' , 'is recognized for creating ChatGPT', 'which is both a priority and a platform for ongoing innovations', 'is planning to enhance its capabilities with the release of GPT-4', 'associated APIs?']\n",
        "->\n",
        "- subquery: What is the name of the organization discussed in TechCrunch articles, despite its financial instability?\n",
        "- subquery: What is the name of the organization recognized for creating ChatGPT?\n",
        "- subquery: What is the name of the organization recognized for creating ChatGPT, which is both a priority and a platform for ongoing innovations?\n",
        "- subquery: What is the name of the organization planning to enhance ChatGPT with the release of GPT-4?\n",
        "- subquery: What is the name of the organization planning to enhance ChatGPT associated APIs?\n",
        "\n",
        "Example:\n",
        "Original Query: \"profit of Apple, Tesla and Microsoft?\"\n",
        "Seperated Parts: ['profit of Apple', 'Tesla', 'Microsoft?']\n",
        "->\n",
        "- subquery: profit of Apple\n",
        "- subquery: profit of Tesla\n",
        "- subquery: profit of Microsoft\n",
        "\n",
        "\n",
        "One more example:\n",
        "Original Query: \"Who is the individual associated with the cryptocurrency industry facing a criminal trial on fraud and conspiracy charges, as reported by both The Verge and TechCrunch, and is accused by prosecutors of committing fraud for personal gain?\"\n",
        "Seperated Parts: ['Who is the individual associated with the cryptocurrency industry facing a criminal trial on fraud', 'conspiracy charges', 'as reported by both The Verge and TechCrunch', 'is accused by prosecutors of committing fraud for personal gain?']\n",
        "->\n",
        "- subquery: Who is the individual associated with the cryptocurrency industry facing a criminal trial on fraud?\n",
        "- subquery: Who is the individual associated with the cryptocurrency industry facing a criminal trial conspiracy charges?\n",
        "- subquery: Who is the individual associated with the cryptocurrency industry as reported by both The Verge and TechCrunch?\n",
        "- subquery: Who is the individual is accused by prosecutors of committing fraud for personal gain?\n",
        "\n",
        "\n",
        "Now, based on the above examples, provide a list of subqueries for each part of the question while preserving the essential meaning.\n",
        "Don't say anything other than the format that starts with this form (- subquery: ). And the decomposed query that is generated can't just generate the original question. Don't forget the purpose of dividing in the original question.\n",
        "\"\"\"\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "mHsAog0iF98_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################MultihopRAG333333333333#####################\n",
        "# 서브쿼리 생성 프롬프트\n",
        "def generate_subqueries2(original_query, split_results):\n",
        "    prompt = f\"\"\"\n",
        "Given a query with multiple entities or phrases separated by conjunctions or commas, create each subquery by keeping as much of the original phrasing as necessary to maintain the intent and meaning of the original query.\n",
        "\n",
        "Instructions:\n",
        "1. For each separated part, complete the meaning of the question using the previous part of the current section.\n",
        "2. Preserve original terminology wherever possible, guaranteeing that each subquery forms a grammatically complete sentence.\n",
        "3. The number of sub-questions created must match the number of separated parts.\n",
        "\n",
        "Original Query: \"{original_query}\"\n",
        "Separated Parts:\n",
        "{split_results}\n",
        "\n",
        "Example:\n",
        "Original Query: \"What is the name of the organization discussed in TechCrunch articles that, despite its financial instability, is recognized for creating ChatGPT, which is both a priority and a platform for ongoing innovations, and is planning to enhance its capabilities with the release of GPT-4 and associated APIs?\"\n",
        "Seperated Parts: ['What is the name of the organization discussed in TechCrunch articles that', 'despite its financial instability' , 'is recognized for creating ChatGPT', 'which is both a priority and a platform for ongoing innovations', 'is planning to enhance its capabilities with the release of GPT-4', 'associated APIs?']\n",
        "->\n",
        "- subquery: What is the name of the organization discussed in TechCrunch articles?\n",
        "- subquery: What is the name of the organization discussed in TechCrunch articles, despite its financial instability?\n",
        "- subquery: What is the name of the organization recognized for creating ChatGPT?\n",
        "- subquery: What is the name of the organization recognized for creating ChatGPT, which is both a priority and a platform for ongoing innovations?\n",
        "- subquery: What is the name of the organization planning to enhance ChatGPT with the release of GPT-4?\n",
        "- subquery: What is the name of the organization planning to enhance ChatGPT associated APIs?\n",
        "\n",
        "Example:\n",
        "Original Query: \"what is profit of Apple, Tesla and Microsoft and non-profit of Nexans?\"\n",
        "Seperated Parts: ['what is profit of Apple', 'Tesla', 'Microsoft','non-profit of Nexans?']\n",
        "->\n",
        "- subquery: what is profit of Apple?\n",
        "- subquery: what is profit of Tesla?\n",
        "- subquery: what is profit of Microsoft?\n",
        "- subquery: what is non-profit of Nexans?\n",
        "\n",
        "\n",
        "One more example:\n",
        "Original Query: \"Who is the individual associated with the cryptocurrency industry facing a criminal trial on fraud and conspiracy charges, as reported by both The Verge and TechCrunch, and is accused by prosecutors of committing fraud for personal gain?\"\n",
        "Seperated Parts: ['Who is the individual associated with the cryptocurrency industry facing a criminal trial on fraud', 'conspiracy charges', 'as reported by both The Verge and TechCrunch', 'is accused by prosecutors of committing fraud for personal gain?']\n",
        "->\n",
        "- subquery: Who is the individual associated with the cryptocurrency industry facing a criminal trial on fraud?\n",
        "- subquery: Who is the individual associated with the cryptocurrency industry facing a criminal trial conspiracy charges?\n",
        "- subquery: Who is the individual associated with the cryptocurrency industry as reported by both The Verge and TechCrunch?\n",
        "- subquery: Who is the individual is accused by prosecutors of committing fraud for personal gain?\n",
        "\n",
        "\n",
        "Now, based on the above examples, provide a list of subqueries for each part of the question while preserving the essential meaning.\n",
        "Don't say anything other than the format that starts with this form (- subquery: ). And the decomposed query that is generated can't just generate the original question. Don't forget the purpose of dividing in the original question.\n",
        "\"\"\"\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "ofuDMJ61vRwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######안쓸거같긴한데\n",
        "#######################MultihopRAG#####################\n",
        "# 서브쿼리 생성 프롬프트\n",
        "def generate_subqueries2(original_query, split_results):\n",
        "    prompt = f\"\"\"\n",
        "Given a query with multiple entities or phrases separated by conjunctions or commas, create each subquery by keeping as much of the original phrasing as necessary to maintain the intent and meaning of the original query.\n",
        "\n",
        "Instructions:\n",
        "1. For each separated part, complete the meaning of the question using the previous part of the current section.\n",
        "2. Preserve original terminology wherever possible, guaranteeing that each subquery forms a grammatically complete sentence.\n",
        "3. The number of sub-questions created must match the number of separated parts.\n",
        "\n",
        "Original Query: \"{original_query}\"\n",
        "Separated Parts:\n",
        "{split_results}\n",
        "\n",
        "\n",
        "Example:\n",
        "Original Query: \"~~A, ~~~B ~~~ and ~~C ~~?\"\n",
        "Seperated Parts: ['~~A', '~~~B ~~~', '~~C ~~?']\n",
        "->\n",
        "- subquery: subqforA\n",
        "- subquery: subqforB\n",
        "- subquery: subqforC\n",
        "\n",
        "Now, based on the above examples, provide a list of subqueries for each part of the question while preserving the essential meaning.\n",
        "Don't say anything other than the format that starts with this form (- subquery: ). And the decomposed query that is generated can't just generate the original question. Don't forget the purpose of dividing in the original question.\n",
        "\"\"\"\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "rQGL_64syF8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6JKPWImPw3G"
      },
      "outputs": [],
      "source": [
        "#################hotpotQA############################\n",
        "# 서브쿼리 생성 프롬프트\n",
        "def generate_subqueries2(original_query, split_results):\n",
        "    prompt = f\"\"\"\n",
        "Given a query with multiple entities or phrases separated by conjunctions or commas, create each subquery by keeping as much of the original phrasing as necessary to maintain the intent and meaning of the original query.\n",
        "\n",
        "Instructions:\n",
        "1. For each phrase or section after a conjunction or comma, create a complete subquery that retains necessary context from the original query.\n",
        "2. Ensure each subquery stands alone with full context so no information or intent is lost, and no subquery is overly simplified.\n",
        "3. Maintain original terms where possible and ensure each subquery is grammatically complete.\n",
        "When you fill in a sentence (subquery) in Separate Parts, always find it in the words in the original question and fill it in.\n",
        "\n",
        "\n",
        "Original Query: \"{original_query}\"\n",
        "Separated Parts:\n",
        "{split_results}\n",
        "\n",
        "Example:\n",
        "Original Query: \"Who has won more awards, Dan Schneider or Helen Hunt?\"\n",
        "->\n",
        "- subquery: Who has won more awards than Helen Hunt?\n",
        "- subquery: Who has won more awards than Dan Schneider?\n",
        "\n",
        "Example:\n",
        "Original Query: \"profit of Apple, Tesla and Microsoft?\"\n",
        "->\n",
        "- subquery: profit of Apple\n",
        "- subquery: profit of Tesla\n",
        "- subquery: profit of Microsoft\n",
        "\n",
        "One more example:\n",
        "Original Query: \"Which American singer and songwriter has a mezzo-soprano vocal range, Tim Armstrong or Tori Amos?\"\n",
        "->\n",
        "- subquery: Which American singer has a mezzo-soprano vocal range?\n",
        "- subquery: Which American songwriter has a mezzo-soprano vocal range?\n",
        "- subquery: Is Tim Armstrong an American singer and songwriter with a mezzo-soprano vocal range?\n",
        "- subquery: Is Tori Amos an American singer and songwriter with a mezzo-soprano vocal range?\n",
        "\n",
        "Now, based on the above examples, provide a list of subqueries for each part of the question while preserving the essential meaning.\n",
        "- subquery: <- Don't say anything other than the format that starts with this form. And the decomposed query that is generated can't just generate the original question. Don't forget the purpose of dividing in the original question.\n",
        "\"\"\"\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1AGRyaogyyL"
      },
      "outputs": [],
      "source": [
        "#################RE####################\n",
        "# 서브쿼리 생성 프롬프트\n",
        "def generate_subqueries2(original_query, split_results):\n",
        "    prompt = f\"\"\"\n",
        "Given a query with multiple entities or phrases separated by conjunctions or commas, create each subquery by keeping as much of the original phrasing as necessary to maintain the intent and meaning of the original query.\n",
        "\n",
        "Instructions:\n",
        "1. For each phrase or section after a conjunction or comma, create a complete subquery that retains necessary context from the original query.\n",
        "2. Ensure each subquery stands alone with full context so no information or intent is lost, and no subquery is overly simplified.\n",
        "3. Maintain original terms where possible and ensure each subquery is grammatically complete.\n",
        "\n",
        "Original Query: \"{original_query}\"\n",
        "Separated Parts:\n",
        "{split_results}\n",
        "\n",
        "Example:\n",
        "Original Query: \"Who's birth date is the first earliest, among the birth date of Neil Armstrong, the pioneering astronaut who became the first human to set foot on the moon during NASA's Apollo 11 mission in 1969, and Taylor Swift and Vladimir Putin?\"\n",
        "Seperated Parts: ['Who's birth date is the first earliest', 'among the birth date of Neil Armstrong', 'the pioneering astronaut who became the first human to set foot on the moon during NASA's Apollo 11 mission in 1969' ,'Taylor Swift' ,'Vladimir Putin?' ]\n",
        "->\n",
        "- subquery: Who's birth date is the first earliest, among the birth date of Neil Armstrong who is the pioneering astronaut who became the first human to set foot on the moon during NASA's Apollo 11 mission in 1969?\n",
        "- subquery: Who's birth date is the first earliest, among the birth date of Taylor Swift?\n",
        "- subquery: Who's birth date is the first earliest, among the birth date of Vladimir Putin?\n",
        "\n",
        "Example:\n",
        "Original Query: \"profit of Apple, Tesla and Microsoft?\"\n",
        "Seperated Parts: ['profit of Apple', 'Tesla', 'Microsoft?']\n",
        "->\n",
        "- subquery: profit of Apple\n",
        "- subquery: profit of Tesla\n",
        "- subquery: profit of Microsoft\n",
        "\n",
        "Example:\n",
        "Original Query: \"What is the name of the organization discussed in TechCrunch articles that, despite its financial instability, is recognized for creating ChatGPT, which is both a priority and a platform for ongoing innovations, and is planning to enhance its capabilities with the release of GPT-4 and associated APIs?\"\n",
        "Seperated Parts: ['What is the name of the organization discussed in TechCrunch articles that', 'despite its financial instability' , 'is recognized for creating ChatGPT', 'which is both a priority and a platform for ongoing innovations', 'is planning to enhance its capabilities with the release of GPT-4', 'associated APIs?']\n",
        "->\n",
        "- subquery: What is the name of the organization discussed in TechCrunch articles, despite its financial instability?\n",
        "- subquery: What is the name of the organization recognized for creating ChatGPT?\n",
        "- subquery: What is the name of the organization recognized for creating ChatGPT, which is both a priority and a platform for ongoing innovations?\n",
        "- subquery: What is the name of the organization planning to enhance ChatGPT with the release of GPT-4?\n",
        "- subquery: What is the name of the organization planning to enhance ChatGPT associated APIs?\n",
        "\n",
        "\n",
        "Now, based on the above examples, provide a list of subqueries for each part of the question while preserving the essential meaning.\n",
        "- subquery: <- Don't say anything other than the format that starts with this form. And the decomposed query that is generated can't just generate the original question. Don't forget the purpose of dividing in the original question.\n",
        "\"\"\"\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM 호출 예시\n",
        "def get_subqueries2(original_query, model=\"gpt-4o\"):\n",
        "    original_query = \"Who's birth date is the first earliest, among the birth date of Neil Armstrong, the first human to set foot on the Moon during the Apollo 11 mission in 1969, whose historic words, \\\"That's one small step for a man, one giant leap for mankind,\\\"marked a significant achievement in space exploration, Taylor Swift, and Chris Hemsworth?\"\n",
        "    split_results = \"['Who's birth date is the first earliest', 'among the birth date of Neil Armstrong', 'the first human to set foot on the Moon during the Apollo 11 mission in 1969', 'whose historic words, \\\"That\\'s one small step for a man, one giant leap for mankind\\\"', 'marked a significant achievement in space exploration', 'Taylor Swift', 'Chris Hemsworth?']\"\n",
        "    #split_results = [part.strip() for part in split_results_input.split(\",\") if part.strip()]\n",
        "\n",
        "    prompt = generate_subqueries2(original_query, split_results)\n",
        "    print(prompt)\n",
        "    response = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0\n",
        "    )\n",
        "\n",
        "    # 각 서브쿼리의 앞에 있는 \"subquery:\"와 \"-\"를 제거하고 리스트로 반환\n",
        "    subqueries = [\n",
        "        query.replace(\"- subquery: \", \"\").strip()  # \"subquery:\" 제거\n",
        "        for query in response.choices[0].message.content.splitlines() if query.strip()\n",
        "    ]\n",
        "    return subqueries"
      ],
      "metadata": {
        "id": "QW9dYZcpAuaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrKizET9cfJp"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}